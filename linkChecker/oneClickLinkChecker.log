AUTHOR:  huan.h.zhou@intel.com
HTMLFILE:  deep-learning-with-avx512-and-dl-boost.html
SENTENCE:  <p>&nbsp; &nbsp; &nbsp;1.融合 FP32 OP 并转换为 INT8 OP。例如 <em>MatMul</em>、<em>BiasAdd</em> 和 <em>ReLU</em> 可以融合为单个量化的全连接层 OP，即 <strong><em>QuantizedMatMulWithBiasAndRelu</em></strong>。不同的神经网络框架所支持的可融合的 OP 不完全相同。稍后将介绍的英特尔&reg; AI Quantization Tools for TensorFlow* 中，可以看到 TensorFlow 支持的可融合 OP 列表如下：<a href="https://github.com/intel/lpot/blob/master/lpot/adaptor/tensorflow.yaml#L190">https://github.com/intel/lpot/blob/master/lpot/adaptor/tensorflow.yaml#L190</a>。</p>
MESSAGE:  404 https://github.com/intel/lpot/blob/master/lpot/adaptor/tensorflow.yaml#L190, 

AUTHOR:  huan.h.zhou@intel.com
HTMLFILE:  deep-learning-with-avx512-and-dl-boost.html
SENTENCE:  <p>pyTorch 支持的可融合 OP 请参阅：<a href="https://github.com/intel/lpot/blob/master/lpot/adaptor/pytorch_cpu.yaml#L124">https://github.com/intel/lpot/blob/master/lpot/adaptor/pytorch_cpu.yaml#L124</a></p>
MESSAGE:  404 https://github.com/intel/lpot/blob/master/lpot/adaptor/pytorch_cpu.yaml#L124, 

AUTHOR:  huan.h.zhou@intel.com
HTMLFILE:  deep-learning-with-avx512-and-dl-boost.html
SENTENCE:  <p>第 3 步：使用脚本 <a href="https://github.com/intel/lpot/blob/master/examples/tensorflow/image_recognition/prepare_dataset.sh">prepare_dataset.sh</a> 将原始数据转化为 <strong>TFrecord</strong> 格式：</p>
MESSAGE:  404 https://github.com/intel/lpot/blob/master/examples/tensorflow/image_recognition/prepare_dataset.sh, 

AUTHOR:  huan.h.zhou@intel.com
HTMLFILE:  deep-learning-with-avx512-and-dl-boost.html
SENTENCE:  <p>编辑文件：<a href="https://github.com/intel/lpot/blob/master/examples/tensorflow/image_recognition/resnet50_v1.yaml">examples/tensorflow/image_recognition/resnet50_v1.yaml</a>，确保 <strong>quantization\calibration</strong>、<strong>evaluation\accuracy</strong> 和 <strong>evaluation\performance</strong> 的数据集路径是用户的真实本地路径。应为之前数据准备阶段生成的 <strong>TFrecord</strong> 数据的所在位置。</p>
MESSAGE:  404 https://github.com/intel/lpot/blob/master/examples/tensorflow/image_recognition/resnet50_v1.yaml, 

AUTHOR:  huan.h.zhou@intel.com
HTMLFILE:  deep-learning-with-avx512-and-dl-boost.html
SENTENCE:  <p><a href="https://docs.openvino.ai/latest/pot_README.html">训练后优化工具套件介绍</a></p>
MESSAGE:  404 https://docs.openvino.ai/latest/pot_README.html, 

AUTHOR:  huan.h.zhou@intel.com
HTMLFILE:  deep-learning-with-avx512-and-dl-boost.html
SENTENCE:  <p><a href="https://docs.openvino.ai/latest/pot_docs_LowPrecisionOptimizationGuide.html">低精确度优化指南</a></p>
MESSAGE:  404 https://docs.openvino.ai/latest/pot_docs_LowPrecisionOptimizationGuide.html, 



AUTHOR:  mulugeta.mammo@intel.com
HTMLFILE:  rocksdb-benchmarking-with-xeon-based-systems.html
SENTENCE:  <p>Source:&nbsp;<a href="https://github.com/mulugetam/rocksdb/blob/aes-encryption/examples/ipp_aes_ctr_example.cc">https://github.com/mulugetam/rocksdb/blob/aes-encryption/examples/ipp_aes_ctr_example.cc</a></p>
MESSAGE:  404 https://github.com/mulugetam/rocksdb/blob/aes-encryption/examples/ipp_aes_ctr_example.cc, 

AUTHOR:  xiang.lin@intel.com
HTMLFILE:  relion-3-1-tuning-guide-on-xeon-based-platforms.html
SENTENCE:  	<li><a href="https://science.sciencemag.org/content/350/6259/404.full?explicitversion=true">Cryo-EM structure of the activated NAIP2-NLRC4 inflammasome reveals nucleated polymerization</a></li>
MESSAGE:  503 https://science.sciencemag.org/content/350/6259/404.full?explicitversion=true, 

AUTHOR:  ruqiu.cao@intel.com
HTMLFILE:  data-compression-tuning-guide-on-xeon-systems.html
SENTENCE:  <p><strong>Intel Intelligent Storage Acceleration Library</strong>&nbsp;helps accelerate and optimize Intel architecture-based storage, and provides optimizations for storage recoverability, data integrity, data security, among others, while accelerating data compression. For more information on ISA-L, please visit&nbsp;<a href="https://01.org/intel%C2%AE-storage-acceleration-library-open-source-version">Intel Storage Acceleration Library</a>.</p>
MESSAGE:  404 https://01.org/intel, 

AUTHOR:  unknown
HTMLFILE:  getting-started-with-intel-optimization-for-mxnet.html
SENTENCE:  <p>Below are the results collected on Intel(R) Xeon(TM) Platinum 8280L @ 2.70GHz with version mxnet-native v1.8.0 and mxnet v1.8.0 (with and without subgraphs optimizations) [<a href="#Benchmark command">1</a>] :</p>
MESSAGE:  404 https://www.intel.com/content/www/us/en/developer/articles/guide/https://www.intel.com/content/www/us/en/developer/articles/guide/getting-started-with-intel-optimization-for-mxnet.html#Benchmark command, 



AUTHOR:  dan.krogh@intel.com
HTMLFILE:  third-generation-xeon-scalable-family-overview.html
SENTENCE:  <p><a href="https://gitlab.devtools.intel.com/wanghuaq/nova-pbf/tree/mixed-cpu/10-14_mixed_cpu">Intel&reg; Speed Select Technology - Base Frequency (Intel&reg; SST-BF) &ndash; source code / API for splitting CPU cores into shared or dedicated sets on Openstack</a></p>
MESSAGE:  [Errno -2] Name or service not known https://gitlab.devtools.intel.com/wanghuaq/nova-pbf/tree/mixed-cpu/10-14_mixed_cpu, 

Total links followed:  578
Total broken links:  11
======================================================
